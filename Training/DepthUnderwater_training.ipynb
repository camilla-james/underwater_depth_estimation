{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install modules"
      ],
      "metadata": {
        "id": "c4nk3WQ-C9aB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvBBKtknCj_e",
        "outputId": "56f6f593-37ab-43d3-868a-ec4fb3ac8fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl5sqcxBCubv",
        "outputId": "d087b29e-2ef2-4d30-f300-fb4b0d4e4b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.5-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.44.1-py2.py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.1/266.1 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.44.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNaUwfbRC4uD",
        "outputId": "94c68edb-af3d-4d5c-e79a-9810587b2b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting peft\n",
            "  Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n",
            "Collecting accelerate>=0.21.0 (from peft)\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate, peft\n",
            "Successfully installed accelerate-0.28.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 peft-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import statments"
      ],
      "metadata": {
        "id": "cbO-re1tDDsj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGWQfKO0BRuf"
      },
      "outputs": [],
      "source": [
        "# standard imports\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# transformers, hugging face\n",
        "import transformers\n",
        "from transformers import AutoImageProcessor, AutoModelForDepthEstimation\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.transforms.functional as fn\n",
        "from torch import nn\n",
        "import requests\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "#torch\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import Subset\n",
        "from torch import nn\n",
        "import torchvision\n",
        "\n",
        "# for training\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import wandb\n",
        "from peft import LoraConfig\n",
        "from peft import get_peft_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "3_J23RYpDjSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download FlSea Dataset"
      ],
      "metadata": {
        "id": "zCWxsYwjGf31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYED7fG9IppY",
        "outputId": "4f626025-5693-480f-9de4-c907b5ec2bcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"/content/drive/MyDrive/MIR_Semester2/FlSeaDataset\"\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "Vz_UbmBRI-Ns",
        "outputId": "c05b5277-462a-4d23-92b9-32574eeb1df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6664e5ba-eff5-4b6a-9ca1-6238c60c59d1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6664e5ba-eff5-4b6a-9ca1-6238c60c59d1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"camillaleahjames\",\"key\":\"d718d2279b5df283011f5dba00781d8f\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "8uGjBQ5sJSjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "3lhdJqFTJXtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjO-hSWPJZnH",
        "outputId": "92e36cfa-20cf-474d-c420-764b98404d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !kaggle datasets download -d viseaonlab/flsea-vi\n",
        "!unzip -q -o /content/flsea-vi.zip -d /content/drive/MyDrive/MIR_Semester2/FlSeaDataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36QSi1jHGlde",
        "outputId": "5d76a8f9-0398-4603-9f1b-215055c0d273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[/content/flsea-vi.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/flsea-vi.zip or\n",
            "        /content/flsea-vi.zip.zip, and cannot find /content/flsea-vi.zip.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FlSeaDataset(Dataset):\n",
        "    def __init__(self, data_dir, label_dir, transforms=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.transforms = transforms\n",
        "        self.image_files = []\n",
        "        self.label_files = []\n",
        "\n",
        "        for root, _, files in os.walk(data_dir):\n",
        "            for file in files:\n",
        "                if file.endswith('.tif') or file.endswith('.tiff'):\n",
        "                    image_file = os.path.join(root, file)\n",
        "                    self.image_files.append(image_file)\n",
        "\n",
        "        for root, _, files in os.walk(label_dir):\n",
        "            for file in files:\n",
        "                if file.endswith('.tif') or file.endswith('.tiff'):\n",
        "                    label_file = os.path.join(root, file)\n",
        "                    self.label_files.append(label_file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_file = self.image_files[index]\n",
        "        label_file = self.label_files[index]\n",
        "\n",
        "        image = Image.open(image_file).convert('RGB')\n",
        "        label = Image.open(label_file)\n",
        "\n",
        "        # mask = (label != 0).astype(int)  # Create binary mask where label is not 0\n",
        "\n",
        "        # image = image * mask\n",
        "\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "            label  = self.transforms(label)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class EiffelTowerDataset(Dataset):\n",
        "    def __init__(self, data_dir, label_dir, transforms=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transforms = transforms\n",
        "        self.image_files = []\n",
        "        self.mask_files = []\n",
        "\n",
        "        for root, _, files in os.walk(data_dir):\n",
        "            for file in files:\n",
        "                if file.endswith('.jpg') or file.endswith('.png'):\n",
        "                    image_file = os.path.join(root, file)\n",
        "                    self.image_files.append(image_file)\n",
        "\n",
        "        for root, _, files in os.walk(label_dir):\n",
        "            for file in files:\n",
        "                if file.endswith('.jpg') or file.endswith('.png'):\n",
        "                    mask_file = os.path.join(root, file)\n",
        "                    self.mask_files.append(mask_file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_file = self.image_files[index]\n",
        "        mask_file = self.mask_files[index]\n",
        "\n",
        "        image = Image.open(image_file).convert('RGB')\n",
        "        mask = Image.open(mask_file)\n",
        "\n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "            mask = self.transforms(mask)\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "3lQjfMJQDpIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "-X-VmwfcDGz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DepthAnythingPEFT:\n",
        "\n",
        "    def __init__(self, model_checkpoint) -> None:\n",
        "        self.model_checkpoint = model_checkpoint\n",
        "        self.image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n",
        "        self.model = AutoModelForDepthEstimation.from_pretrained(model_checkpoint,\n",
        "        ignore_mismatched_sizes=True,)  # provide this in case you're planning to fine-tune an already fine-tuned checkpoint\n",
        "\n",
        "\n",
        "    def trainable_parameters(self, model):\n",
        "        trainable_params = 0\n",
        "        all_param = 0\n",
        "        for _, param in model.named_parameters():\n",
        "            all_param += param.numel()\n",
        "            if param.requires_grad:\n",
        "                trainable_params += param.numel()\n",
        "        print(\n",
        "            f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
        "        )\n",
        "\n",
        "    def trainable_modules(self,model):\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                print(name, param.shape)\n",
        "\n",
        "\n",
        "    def peft_model(self, peft_config):\n",
        "        return get_peft_model(self.model, peft_config)"
      ],
      "metadata": {
        "id": "HN3WjlGIEA0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training function"
      ],
      "metadata": {
        "id": "UOpeCkNODO_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PEFTTraining:\n",
        "\n",
        "    def __init__(self, model_checkpoint: str,output_dir: str, model, train_dataset: Dataset,\n",
        "                 valid_dataset: Dataset, train_batch_size:int, valid_batch_size:int ,\n",
        "                 loss_fn, optimizer, epoch: int, device, warmup_period_percentage,\n",
        "                 learning_rate,min_lr,grad_clip, wandb_logging = True) -> None:\n",
        "\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.model = model\n",
        "        self.epoch = epoch\n",
        "        self.output_dir = output_dir\n",
        "        self.logging = wandb_logging\n",
        "        self.eval = EvaluationMetric(wandb_logging)\n",
        "        self.device = device\n",
        "        self.model.to(self.device)\n",
        "        self.train_batch_size = train_batch_size\n",
        "        self.model_name = model_checkpoint.split(\"/\")[-1]\n",
        "        self.training_loader = torch.utils.data.DataLoader(train_dataset, batch_size= train_batch_size, shuffle=True)\n",
        "        self.validation_loader = torch.utils.data.DataLoader(valid_dataset, batch_size= valid_batch_size, shuffle=False)\n",
        "        self.num_steps = len(self.training_loader) * self.epoch\n",
        "        self.learning_rate = learning_rate\n",
        "        self.min_lr = min_lr\n",
        "        self.grad_clip = grad_clip\n",
        "        self.iter_per_epoch = len(train_dataset)/train_batch_size\n",
        "        self.lr_decay_iters = int(self.iter_per_epoch * epoch) + 1\n",
        "        self.warmup_period = self.lr_decay_iters*warmup_period_percentage/100\n",
        "        # self.lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(self.optimizer, T_0=T_0, T_mult=T_mult)\n",
        "        # self.warmup_scheduler = warmup.LinearWarmup(self.optimizer, warmup_period=self.warmup_period)\n",
        "\n",
        "    # learning rate decay scheduler (cosine with warmup)\n",
        "    def get_lr(self,iteration):\n",
        "        # 1) linear warmup for warmup_iters steps\n",
        "        if iteration < self.warmup_period:\n",
        "            return self.learning_rate * iteration / self.warmup_period\n",
        "        # 2) if it > lr_decay_iters, return min learning rate\n",
        "        if iteration > self.lr_decay_iters:\n",
        "            return self.min_lr\n",
        "        # 3) in between, use cosine decay down to min learning rate\n",
        "        decay_ratio = (iteration - self.warmup_period) / (self.lr_decay_iters - self.warmup_period)\n",
        "        assert 0 <= decay_ratio <= 1\n",
        "        coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio)) # coeff ranges 0..1\n",
        "        return self.min_lr + coeff * (self.learning_rate - self.min_lr)\n",
        "\n",
        "\n",
        "    def train_one_epoch(self, epoch_index):\n",
        "        running_loss = 0.\n",
        "        last_loss = 0.\n",
        "\n",
        "        # Here, we use enumerate(training_loader) instead of\n",
        "        # iter(training_loader) so that we can track the batch\n",
        "        # index and do some intra-epoch reporting\n",
        "        iteration = epoch_index * self.iter_per_epoch\n",
        "        for i, (inputs, labels) in enumerate(self.training_loader):\n",
        "            # Every data instance is an input + label pair\n",
        "            inputs, labels = inputs.to(self.device),labels.to(self.device)\n",
        "\n",
        "            # determine and set the learning rate for this iteration\n",
        "            lr = self.get_lr(iteration)\n",
        "            self.optimizer.param_groups[0][\"lr\"] = lr\n",
        "\n",
        "            # clip the gradient\n",
        "            if self.grad_clip != 0.0:\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip)\n",
        "\n",
        "            # Zero your gradients for every batch!\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            # Make predictions for this batch\n",
        "            outputs = self.model(inputs).predicted_depth\n",
        "\n",
        "            # Compute the loss and its gradients\n",
        "\n",
        "            loss = self.loss_fn(torch.squeeze(outputs), torch.squeeze(labels))\n",
        "            loss.backward()\n",
        "\n",
        "            # Adjust learning weights\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # with self.warmup_scheduler.dampening():\n",
        "            #     if self.warmup_scheduler.last_step + 1 >= self.warmup_period:\n",
        "            #         self.lr_scheduler.step()\n",
        "\n",
        "            # Gather data and report\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            iteration += 1\n",
        "            if i % self.train_batch_size == self.train_batch_size - 1:\n",
        "                last_loss = running_loss / self.train_batch_size\n",
        "                print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "                #wb_x = epoch_index * len(self.training_loader) + i + 1\n",
        "                wandb.log({'Loss/train (per batch)': last_loss})\n",
        "                wandb.log({'Learning Rate (per batch)':  self.optimizer.param_groups[0][\"lr\"]})\n",
        "                running_loss = 0.\n",
        "\n",
        "        return last_loss\n",
        "\n",
        "\n",
        "\n",
        "    def train(self,wandb_init = None):\n",
        "\n",
        "        epoch_number = 0\n",
        "\n",
        "        best_vloss = 1_000_000.\n",
        "\n",
        "        for epoch in range(self.epoch):\n",
        "            print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "            # Make sure gradient tracking is on, and do a pass over the data\n",
        "            self.model.train(True)\n",
        "            avg_loss = self.train_one_epoch(epoch_number)\n",
        "\n",
        "\n",
        "            running_vloss = 0.0\n",
        "            # Set the model to evaluation mode, disabling dropout and using population\n",
        "            # statistics for batch normalization.\n",
        "            self.model.eval()\n",
        "\n",
        "            # Disable gradient computation and reduce memory consumption.\n",
        "            with torch.no_grad():\n",
        "                for i, (vinputs, vlabels) in enumerate(self.validation_loader):\n",
        "                    vinputs, vlabels = vinputs.to(self.device),vlabels.to(self.device)\n",
        "                    voutputs = self.model(vinputs).predicted_depth\n",
        "                    vloss = self.loss_fn(torch.squeeze(voutputs), torch.squeeze(vlabels))\n",
        "                    self.eval.compute_metrics(vinputs,voutputs,vlabels)\n",
        "                    running_vloss += vloss\n",
        "\n",
        "            avg_vloss = running_vloss / (i + 1)\n",
        "            print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "            # Log the running loss averaged per batch\n",
        "            # for both training and validation\n",
        "            if self.logging == True:\n",
        "                wandb.log({ 'Training Loss' : avg_loss, 'Validation Loss' : avg_vloss })\n",
        "\n",
        "            # Track best performance, and save the model's state\n",
        "            if avg_vloss < best_vloss:\n",
        "                best_vloss = avg_vloss\n",
        "                if not os.path.exists(self.output_dir):\n",
        "                    os.makedirs(self.output_dir)\n",
        "\n",
        "                model_path = '{}/{}_{}.pth'.format(self.output_dir, self.model_name, epoch_number)\n",
        "                torch.save({'epoch': epoch_number,\n",
        "                            'model_state_dict': self.model.state_dict(),\n",
        "                            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                            'loss': best_vloss},\n",
        "                            model_path)\n",
        "\n",
        "                if self.logging == True:\n",
        "                    if wandb_init is not None:\n",
        "                        artifact = wandb.Artifact('model', type='model')\n",
        "                        artifact.add_file(model_path)\n",
        "                        wandb_init.log_artifact(artifact)\n",
        "                    else:\n",
        "                        print(\"No WandB init given; model artifact is not saved\")\n",
        "\n",
        "\n",
        "            epoch_number += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "HLHW3nX2EBr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation + Metrics"
      ],
      "metadata": {
        "id": "3aDTBFkbDaWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb login\n",
        "# afcce06a15ac3cc4cb2deb7200670d496bcce144 -> api key"
      ],
      "metadata": {
        "id": "i7AfN7CwE9xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import (\n",
        "    Compose,\n",
        "    RandomHorizontalFlip,\n",
        "    RandomResizedCrop,\n",
        "    ToTensor,\n",
        ")\n",
        "\n",
        "### Config\n",
        "EXPERIMENT_NUM = 41\n",
        "MODEL_CHECKPOINT = \"LiheYoung/depth-anything-small-hf\"\n",
        "DATASET_ROOT_DIR = \"eiffel/2020/images/\"\n",
        "OUTPUT_DIR = f\"DepthAnythingPEFT/depth-anything-small-lora_{EXPERIMENT_NUM}\"\n",
        "WANDB_USER = \"researchpapers\"\n",
        "WANDB_PROJECT = \"peft_training\"\n",
        "WANDB_DATASET = \"USOD10k\"\n",
        "\n",
        "### Hyperparameters\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "DATA_USE_PERCENTAGE = 100\n",
        "TRAIN_SPLIT = 0.8\n",
        "\n",
        "LOSS = nn.L1Loss()\n",
        "OPTIM = \"AdamW\"\n",
        "EPOCH = 1\n",
        "LORA_RANK = 32\n",
        "LORA_ALPHA = 64\n",
        "LORA_DROPOUT = 0.001\n",
        "BIAS = \"lora_only\"\n",
        "GRAD_CLIP = 1.0\n",
        "MIN_LR = 1e-7\n",
        "\n",
        "### Grid Search\n",
        "LEARNING_RATE_LIST = [0.001,0.01,0.0001]\n",
        "WARMUP_PERIOD_PERCENTAGE_LIST = [10,20,30,40,50]\n",
        "\n",
        "\n",
        "model = DepthAnythingPEFT(model_checkpoint = MODEL_CHECKPOINT)\n",
        "\n",
        "#consider changing the transform\n",
        "data_transforms = Compose(\n",
        "    [\n",
        "        RandomResizedCrop(model.image_processor.size[\"height\"]),\n",
        "        RandomHorizontalFlip(),\n",
        "        ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "dataset = EiffelTowerDataset('eiffel/2020/images/','eiffel/2020/depth/dense/depth', transforms=data_transforms)\n",
        "useful_dataset_length = int(len(dataset) * DATA_USE_PERCENTAGE /100)\n",
        "print(f\"Length of Dataset: {useful_dataset_length}\")\n",
        "train_size = int(TRAIN_SPLIT * useful_dataset_length)\n",
        "valid_size = useful_dataset_length - train_size\n",
        "useful_dataset = Subset(dataset,list(range(useful_dataset_length)))\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(useful_dataset, [train_size, valid_size])\n",
        "\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    r=LORA_RANK,\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    target_modules=[\"query\", \"value\"],\n",
        "    lora_dropout= LORA_DROPOUT,\n",
        "    bias= BIAS,\n",
        "    modules_to_save=[\"decode_head\"],\n",
        ")\n",
        "\n",
        "\n",
        "for LEARNING_RATE in LEARNING_RATE_LIST:\n",
        "\n",
        "    for WARMUP_PERIOD_PERCENTAGE in WARMUP_PERIOD_PERCENTAGE_LIST:\n",
        "\n",
        "        lora_model = model.peft_model(peft_config)\n",
        "        model.trainable_parameters(lora_model)\n",
        "\n",
        "        if OPTIM == \"AdamW\":\n",
        "            optimizer = torch.optim.AdamW(lora_model.parameters(), lr= LEARNING_RATE)\n",
        "\n",
        "        elif OPTIM == \"SGD\":\n",
        "            optimizer = torch.optim.SGD(lora_model.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "        elif OPTIM == \"ADAM\":\n",
        "            optimizer = torch.optim.Adam(lora_model.parameters(), lr= LEARNING_RATE)\n",
        "\n",
        "        else:\n",
        "            print(\"Optimizer not yet implemented\")\n",
        "\n",
        "\n",
        "        user = WANDB_USER\n",
        "        project = WANDB_PROJECT\n",
        "        display_name = f\"{WANDB_DATASET} lr: {LEARNING_RATE}, warmup: {WARMUP_PERIOD_PERCENTAGE}\"\n",
        "        config = {\"lr\": LEARNING_RATE, \"batch_size\": TRAIN_BATCH_SIZE, \"data_used(%)\" : DATA_USE_PERCENTAGE, \"train_split\": TRAIN_SPLIT, \"loss\": \"mse\",\n",
        "                \"optimizer\" : OPTIM, \"epoch\": EPOCH, \"lora_rank\": LORA_RANK, \"lora_alpha\": LORA_ALPHA, \"lora_dropout\" :LORA_DROPOUT, \"bias\":BIAS,\n",
        "                \"warmup_period\":WARMUP_PERIOD_PERCENTAGE,\"min_lr\": MIN_LR,\"grad_clip\" :GRAD_CLIP}\n",
        "\n",
        "        logger = wandb.init(entity=user, project=project, name=display_name, config=config)\n",
        "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        trainer = PEFTTraining(MODEL_CHECKPOINT,OUTPUT_DIR,lora_model,train_dataset,valid_dataset,\n",
        "                            TRAIN_BATCH_SIZE, VALID_BATCH_SIZE, LOSS, optimizer, EPOCH, device,\n",
        "                            WARMUP_PERIOD_PERCENTAGE,LEARNING_RATE,MIN_LR,GRAD_CLIP, True)\n",
        "\n",
        "\n",
        "\n",
        "        trainer.train(logger)\n",
        "        logger.finish()\n",
        "        EXPERIMENT_NUM +=1class EvaluationMetric:\n",
        "\n",
        "    def __init__(self, wandb_logging:bool) -> None:\n",
        "        self.logging = wandb_logging\n",
        "\n",
        "\n",
        "    def scale_offset(self, y_pred, y_true):\n",
        "        scale_factor = np.mean(y_pred) / np.mean(y_true)\n",
        "\n",
        "        # Adjust the second depth map by the scale factor\n",
        "        true_scaled = y_pred * scale_factor\n",
        "\n",
        "         # Calculate the offset\n",
        "        offset = np.mean(y_pred) - (scale_factor * np.mean(y_true))\n",
        "\n",
        "        # Adjust the second depth map by the offset\n",
        "        true_adjusted = true_scaled + offset\n",
        "\n",
        "        val_min = y_pred.min()\n",
        "        val_range = y_pred.max() - val_min + 1e-7\n",
        "\n",
        "        pred_normed = (y_pred - val_min) / val_range\n",
        "\n",
        "        # apply identical normalization to the denoised image (important!)\n",
        "        true_adjusted_normed = (true_adjusted - val_min) / val_range\n",
        "\n",
        "        return pred_normed, true_adjusted_normed\n",
        "\n",
        "    def absolute_relative_error(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Calculate the Absolute Relative Error (MARE).\n",
        "\n",
        "        Parameters:\n",
        "        y_pred : torch.Tensor\n",
        "            Predicted depth values.\n",
        "        y_true : torch.Tensor\n",
        "            Ground truth depth values.\n",
        "\n",
        "        Returns:\n",
        "        float\n",
        "        Absolute Relative Error (MARE).\n",
        "        \"\"\"\n",
        "        y_pred, y_true = self.scale_offset(y_pred, y_true)\n",
        "        # mask = y_true == 0\n",
        "        # y_true[mask] = 1\n",
        "        absolute_relative_error = np.abs(y_pred - y_true) / y_true\n",
        "\n",
        "        return np.mean(absolute_relative_error)\n",
        "\n",
        "    def root_mean_squared_error(self, y_pred, y_true, log = False):\n",
        "\n",
        "        y_pred, y_true = self.scale_offset(y_pred, y_true)\n",
        "        if log:\n",
        "            y_pred = np.log(y_pred)\n",
        "            y_true = np.log(y_true)\n",
        "        mse = np.mean((y_pred - y_true)**2)\n",
        "        rmse = np.sqrt(mse)\n",
        "        return rmse\n",
        "\n",
        "    def delta1_metric(self, y_pred, y_true, threshold=1.25):\n",
        "        \"\"\"\n",
        "        Calculate the δ1 metric for monocular depth estimation.\n",
        "\n",
        "        Parameters:\n",
        "        y_pred : torch.Tensor\n",
        "            Predicted depth values.\n",
        "        y_true : torch.Tensor\n",
        "            Ground truth depth values.\n",
        "        threshold : float, optional\n",
        "            Threshold for considering a pixel as correctly estimated (default is 1.25).\n",
        "\n",
        "        Returns:\n",
        "        float\n",
        "            Percentage of pixels for which max(d*/d, d/d*) < threshold.\n",
        "\n",
        "        \"\"\"\n",
        "        y_pred, y_true = self.scale_offset(y_pred, y_true)\n",
        "        # Compute element-wise ratios\n",
        "        ratio_1 = y_true / (y_pred + 1e-7)  # Adding epsilon to avoid division by zero\n",
        "        ratio_2 = (y_pred + 1e-7) / y_true  # Adding epsilon to avoid division by zero\n",
        "\n",
        "        # Calculate element-wise maximum ratio\n",
        "        max_ratio = torch.max(ratio_1, ratio_2)\n",
        "\n",
        "        # Count the number of pixels where max_ratio < threshold\n",
        "        num_correct_pixels = torch.sum(max_ratio < threshold).item()\n",
        "\n",
        "        # Calculate the percentage of pixels satisfying the condition\n",
        "        total_pixels = y_true.numel()\n",
        "        percentage_correct = (num_correct_pixels / total_pixels) * 100.0\n",
        "\n",
        "        return percentage_correct\n",
        "\n",
        "    def si_log(y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Calculate the Scale Invarient error that takes into account the global scale of a scene.\n",
        "        This metric is sensitive to the relationships between points in the scene,\n",
        "        irrespective of the absolute global scale.\n",
        "\n",
        "        Parameters:\n",
        "        y_pred : torch.Tensor\n",
        "            Predicted depth values.\n",
        "        y_true : torch.Tensor\n",
        "            Ground truth depth values.\n",
        "\n",
        "        Returns:\n",
        "        float\n",
        "            SI Error\n",
        "\n",
        "        \"\"\"\n",
        "        bs = y_pred.shape[0]\n",
        "\n",
        "        y_pred = torch.reshape(y_pred, (bs, -1))\n",
        "        y_true = torch.reshape(y_true, (bs, -1))\n",
        "\n",
        "        mask = y_true > 0  # 0=missing y_true\n",
        "        num_vals = mask.sum(dim=1)\n",
        "\n",
        "        log_diff = torch.zeros_like(y_pred)\n",
        "        log_diff[mask] = torch.log(y_pred[mask]) - torch.log(y_true[mask])\n",
        "\n",
        "        si_log_unscaled = torch.sum(log_diff**2, dim=1) / num_vals - (torch.sum(log_diff, dim=1)**2) / (num_vals**2)\n",
        "        si_log_score = torch.sqrt(si_log_unscaled) * 100\n",
        "\n",
        "        si_log_score = torch.mean(si_log_score)\n",
        "        return si_log_score\n",
        "\n",
        "    def compute_metrics(self, input_image, outputs, labels):\n",
        "        metrics = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predicted_depth = outputs\n",
        "            img_size = fn.get_image_size(input_image)\n",
        "            img_size.reverse()\n",
        "            prediction = torch.nn.functional.interpolate(\n",
        "            predicted_depth.unsqueeze(1),\n",
        "            size = img_size,\n",
        "            mode = \"bicubic\",\n",
        "            align_corners=False)\n",
        "\n",
        "            # Convert depth prediction to numpy array and resize to match ground truth depth map size\n",
        "            depth_output = prediction.squeeze().cpu().numpy()\n",
        "            labels = labels.squeeze().cpu().numpy()\n",
        "\n",
        "            # Handle invalid or unexpected depth values\n",
        "            depth_output[depth_output <= 0] = 1e-7  # Replace negative or zero values with a small epsilon\n",
        "            labels[labels <= 0] = 1e-7\n",
        "\n",
        "            # Calculate metrics\n",
        "            absRel = self.absolute_relative_error(depth_output, labels)\n",
        "\n",
        "            rmse = self.root_mean_squared_error(depth_output, labels)\n",
        "            rmseLog = self.root_mean_squared_error(depth_output, labels, log = True)\n",
        "\n",
        "            out_t = torch.from_numpy(depth_output)\n",
        "            labels_t = torch.from_numpy(labels)\n",
        "\n",
        "            delta1 = np.mean(self.delta1_metric(out_t, labels_t))\n",
        "            si_error = self.si_log(out_t, labels_t)\n",
        "\n",
        "\n",
        "            if self.logging == True:\n",
        "                wandb.log({\"Absolute Relative error (AbsRel)\": absRel})\n",
        "                wandb.log({\"Root Mean Squared Error (RMSE)\": rmse})\n",
        "                wandb.log({\"Log Root Mean Squared Error (Log-RMSE)\": rmseLog})\n",
        "                wandb.log({\"Scale Invarient Error (SI Error)\": si_error})\n",
        "                wandb.log({\"Delta1 with thresold=1.25\": delta1})\n",
        "\n",
        "            metrics.append([absRel, rmse, rmseLog, si_error, delta1])\n",
        "\n",
        "            return metrics\n"
      ],
      "metadata": {
        "id": "IWIYJ6FPEJOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model configuration and experiments"
      ],
      "metadata": {
        "id": "vNZnujUCDbZn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "61yS2GnqDGek"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}