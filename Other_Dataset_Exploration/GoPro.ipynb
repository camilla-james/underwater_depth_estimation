{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# external imports\n",
    "import transformers\n",
    "from transformers import AutoImageProcessor, AutoModelForDepthEstimation\n",
    "import torch\n",
    "import torchvision\n",
    "import time \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import requests\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoPro with DepthAnything\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|█████████████████████████████████████████████████████████████| 176/176 [14:05<00:00,  4.80s/it]\n"
     ]
    }
   ],
   "source": [
    "# Set this to True to avoid errors with truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "image_folder = \"C:\\\\Users\\\\susan\\\\Documents\\\\University\\\\MIR\\\\DataDriven\\\\GOPRO\\\\images\\\\\"\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "results_folder = \"C:\\\\Users\\\\susan\\\\Documents\\\\University\\\\MIR\\\\DataDriven\\\\GOPRO\\\\processed_images\\\\depth_maps_large\\\\\"\n",
    "pretty_folder = \"C:\\\\Users\\\\susan\\\\Documents\\\\University\\\\MIR\\\\DataDriven\\\\GOPRO\\\\processed_images\\\\pretty_large\\\\\"\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"LiheYoung/depth-anything-large-hf\")\n",
    "model = AutoModelForDepthEstimation.from_pretrained(\"LiheYoung/depth-anything-large-hf\")\n",
    "\n",
    "# Move model and image processor to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "for filename in tqdm(image_files, desc=\"Processing images\"):\n",
    "    image_path = os.path.join(image_folder, filename)\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    already_processed = False\n",
    "    # skip if already done\n",
    "    for root, dirs, files in os.walk(pretty_folder):\n",
    "        for file in files:\n",
    "            if filename==file:\n",
    "               already_processed = True\n",
    "\n",
    "    if already_processed:\n",
    "       continue\n",
    "\n",
    "    \n",
    "    # Prepare image for the model\n",
    "    inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "    # Move to GPU\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    " \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predicted_depth = outputs.predicted_depth\n",
    "    \n",
    "    # interpolate to original size\n",
    "    prediction = torch.nn.functional.interpolate(\n",
    "        predicted_depth.unsqueeze(1),\n",
    "        size=image.size[::-1],\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "    \n",
    "    # save the prediction\n",
    "    output = prediction.squeeze().cpu().numpy()\n",
    "    formatted = (output * 255 / np.max(output)).astype(\"uint8\")\n",
    "    depth = Image.fromarray(formatted)\n",
    "    depth.save(os.path.join(results_folder, filename))\n",
    "    \n",
    "    # save the prediction in a pretty way\n",
    "    fig, ax = plt.subplots(1, 2, dpi=400)\n",
    "    \n",
    "    ax[0].imshow(image)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('GoPro')\n",
    "    ax[1].imshow(depth, cmap= 'plasma')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('DepthAnything')\n",
    "    \n",
    "    fig.savefig(os.path.join(pretty_folder, filename))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|█████████████████████████████████████████████████████████████| 176/176 [07:15<00:00,  2.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# Set this to True to avoid errors with truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "image_folder = \"C:\\\\Users\\\\susan\\\\Documents\\\\University\\\\MIR\\\\DataDriven\\\\GOPRO\\\\images\\\\\"\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "results_folder = \"C:\\\\Users\\\\susan\\\\Documents\\\\University\\\\MIR\\\\DataDriven\\\\GOPRO\\\\processed_images\\\\depth_maps_small\\\\\"\n",
    "pretty_folder = \"C:\\\\Users\\\\susan\\\\Documents\\\\University\\\\MIR\\\\DataDriven\\\\GOPRO\\\\processed_images\\\\pretty_small\\\\\"\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"LiheYoung/depth-anything-small-hf\")\n",
    "model = AutoModelForDepthEstimation.from_pretrained(\"LiheYoung/depth-anything-small-hf\")\n",
    "\n",
    "# Move model and image processor to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "for filename in tqdm(image_files, desc=\"Processing images\"):\n",
    "    image_path = os.path.join(image_folder, filename)\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    already_processed = False\n",
    "    # skip if already done\n",
    "    for root, dirs, files in os.walk(pretty_folder):\n",
    "        for file in files:\n",
    "            if filename==file:\n",
    "               already_processed = True\n",
    "\n",
    "    if already_processed:\n",
    "       continue\n",
    "\n",
    "    \n",
    "    # Prepare image for the model\n",
    "    inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "    # Move to GPU\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predicted_depth = outputs.predicted_depth\n",
    "    \n",
    "    # interpolate to original size\n",
    "    prediction = torch.nn.functional.interpolate(\n",
    "        predicted_depth.unsqueeze(1),\n",
    "        size=image.size[::-1],\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "    \n",
    "    # save the prediction\n",
    "    output = prediction.squeeze().cpu().numpy()\n",
    "    formatted = (output * 255 / np.max(output)).astype(\"uint8\")\n",
    "    depth = Image.fromarray(formatted)\n",
    "    depth.save(os.path.join(results_folder, filename))\n",
    "\n",
    "    # save the prediction in a pretty way\n",
    "    fig, ax = plt.subplots(1, 2, dpi=400)\n",
    "    \n",
    "    ax[0].imshow(image)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('GoPro')\n",
    "    ax[1].imshow(depth, cmap= 'plasma')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('DepthAnything')\n",
    "    \n",
    "    fig.savefig(os.path.join(pretty_folder, filename))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image processor and model\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"LiheYoung/depth-anything-large-hf\")\n",
    "model = AutoModelForDepthEstimation.from_pretrained(\"LiheYoung/depth-anything-large-hf\")\n",
    "\n",
    "# Move model and image processor to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load video\n",
    "filename = \"GH010032.mp4\"\n",
    "folder = \"C:\\\\Users\\\\susan\\\\Documents\\\\University\\\\MIR\\\\DataDriven\\\\GOPRO\\\\\"\n",
    "video = os.path.join(folder, filename)\n",
    "cap = cv2.VideoCapture(video)  # creates a video capture object cap\n",
    "\n",
    "# Define output video writer\n",
    "filename_with_depth = filename[:-4] + \"_depth.avi\"\n",
    "output_video_path = os.path.join(folder, filename_with_depth)\n",
    "\n",
    "# set variables\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)  \n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'XVID'), fps, (frame_width, frame_height))  # creates a VideoWriter \n",
    "                                        # object out that will be used to write frames with depth information to an output video file.\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert frame to PIL image\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(frame)\n",
    "\n",
    "    # Prepare image for the model\n",
    "    inputs = image_processor(images=pil_image, return_tensors=\"pt\")\n",
    "    # Move inputs to GPU\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predicted_depth = outputs.predicted_depth\n",
    "\n",
    "    # Interpolate to original size\n",
    "    prediction = torch.nn.functional.interpolate(\n",
    "        predicted_depth.unsqueeze(1),\n",
    "        size=(frame_height, frame_width),\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "\n",
    "    # Convert depth prediction to numpy array\n",
    "    depth_map = prediction.squeeze().cpu().numpy()\n",
    "\n",
    "    # Normalize depth map for visualization\n",
    "    depth_map = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min()) * 255\n",
    "\n",
    "    # Convert depth map to uint8\n",
    "    depth_map = depth_map.astype(np.uint8)\n",
    "\n",
    "    # Apply the \"plasma\" colormap to the depth map\n",
    "    depth_map_colored = cv2.applyColorMap(depth_map, cv2.COLORMAP_PLASMA)\n",
    "\n",
    "    # Write frame with depth map to output video\n",
    "    out.write(depth_map_colored)\n",
    "    \n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
