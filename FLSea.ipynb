{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# external imports\n",
    "import transformers\n",
    "from transformers import AutoImageProcessor, AutoModelForDepthEstimation\n",
    "import torch\n",
    "import torchvision\n",
    "import time \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import requests\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoPro with DepthAnything\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|█████████████████████████████████████████████████████████████| 176/176 [14:05<00:00,  4.80s/it]\n"
     ]
    }
   ],
   "source": [
    "# Set this to True to avoid errors with truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "image_folder = \"C:\\\\Users\\\\susan\\\\Documents\\\\University\\\\MIR\\\\DataDriven\\\\FLSea\\\\FLSea\\\\canyons\\\\tiny_canyon\\\\tiny_canyon\\\\imgs\"\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "results_folder = \"C:\\\\Users\\\\susan\\\\Documents\\\\University\\\\MIR\\\\DataDriven\\\\FLSea\\\\processed\\\\depth_maps_large\\\\\"\n",
    "pretty_folder = \"C:\\\\Users\\\\susan\\\\Documents\\\\University\\\\MIR\\\\DataDriven\\\\FLSea\\\\processed\\\\pretty_large\\\\\"\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"LiheYoung/depth-anything-large-hf\")\n",
    "model = AutoModelForDepthEstimation.from_pretrained(\"LiheYoung/depth-anything-large-hf\")\n",
    "\n",
    "# Move model and image processor to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "for filename in tqdm(image_files, desc=\"Processing images\"):\n",
    "    image_path = os.path.join(image_folder, filename)\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    already_processed = False\n",
    "    # skip if already done\n",
    "    for root, dirs, files in os.walk(pretty_folder):\n",
    "        for file in files:\n",
    "            if filename==file:\n",
    "               already_processed = True\n",
    "\n",
    "    if already_processed:\n",
    "       continue\n",
    "\n",
    "    \n",
    "    # Prepare image for the model\n",
    "    inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "    # Move to GPU\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    " \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predicted_depth = outputs.predicted_depth\n",
    "    \n",
    "    # interpolate to original size\n",
    "    prediction = torch.nn.functional.interpolate(\n",
    "        predicted_depth.unsqueeze(1),\n",
    "        size=image.size[::-1],\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "    \n",
    "    # save the prediction\n",
    "    output = prediction.squeeze().cpu().numpy()\n",
    "    formatted = (output * 255 / np.max(output)).astype(\"uint8\")\n",
    "    depth = Image.fromarray(formatted)\n",
    "    depth.save(os.path.join(results_folder, filename))\n",
    "    \n",
    "    ground_name = filename[:-5] + \"_SeaErra_abs_depth.tif\"\n",
    "    ground_truth_path = os.path.join(depth_folder, ground_name)\n",
    "    gt_image = Image.open(ground_truth_path)\n",
    "    gt = np.array(gt_image)\n",
    "    formatted_gt = (gt * 255 / np.max(output)).astype(\"uint8\")\n",
    "    ground_truth = Image.fromarray(formatted_gt)\n",
    "    \n",
    "    # save the prediction in a pretty way\n",
    "    fig, ax = plt.subplots(1, 3, dpi=400)\n",
    "\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('FLSea')\n",
    "    ax[1].imshow(depth, cmap= 'plasma')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('DepthAnything')\n",
    "    ax[2].imshow(ground_truth, cmap= 'plasma_r')\n",
    "    ax[2].axis('off')\n",
    "    ax[2].set_title('Ground Truth')\n",
    "    \n",
    "    fig.savefig(os.path.join(pretty_folder, filename))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|███████████████████████████████████████████████████████████| 1012/1012 [07:41<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set this to True to avoid errors with truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "image_folder = \"C:\\\\Users\\\\susan\\\\Documents\\\\University\\\\MIR\\\\DataDriven\\\\FLSea\\\\canyons\\\\tiny_canyon\\\\tiny_canyon\\\\imgs\"\n",
    "image_files = os.listdir(image_folder)\n",
    "# 16233165812779584\n",
    "\n",
    "depth_folder = \"C:\\\\Users\\\\susan\\\\Documents\\\\University\\\\MIR\\\\DataDriven\\\\FLSea\\\\canyons\\\\tiny_canyon\\\\tiny_canyon\\\\depth\"\n",
    "# depth_files = os.listdir(depth_folder)\n",
    "\n",
    "# 16233165812779584_SeaErra_abs_depth\n",
    "\n",
    "results_folder = \"C:\\\\Users\\\\susan\\\\Documents\\\\University\\\\MIR\\\\DataDriven\\\\FLSea\\\\processed\\\\depth_maps_small\\\\\"\n",
    "pretty_folder = \"C:\\\\Users\\\\susan\\\\Documents\\\\University\\\\MIR\\\\DataDriven\\\\FLSea\\\\processed\\\\pretty_small\\\\\"\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"LiheYoung/depth-anything-small-hf\")\n",
    "model = AutoModelForDepthEstimation.from_pretrained(\"LiheYoung/depth-anything-small-hf\")\n",
    "\n",
    "# Move model and image processor to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "for filename in tqdm(image_files, desc=\"Processing images\"):\n",
    "    image_path = os.path.join(image_folder, filename)\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    already_processed = False\n",
    "    # skip if already done\n",
    "    ##for root, dirs, files in os.walk(pretty_folder):\n",
    "    #    for file in files:\n",
    "    #       if filename==file:\n",
    "        #       already_processed = True\n",
    "#\n",
    "   # if already_processed:\n",
    "    #   continue\n",
    "\n",
    "    \n",
    "    # Prepare image for the model\n",
    "    inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "    # Move to GPU\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predicted_depth = outputs.predicted_depth\n",
    "    \n",
    "    # interpolate to original size\n",
    "    prediction = torch.nn.functional.interpolate(\n",
    "        predicted_depth.unsqueeze(1),\n",
    "        size=image.size[::-1],\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "    \n",
    "    # save the prediction\n",
    "    output = prediction.squeeze().cpu().numpy()\n",
    "    formatted = (output * 255 / np.max(output)).astype(\"uint8\")\n",
    "    depth = Image.fromarray(formatted)\n",
    "    depth.save(os.path.join(results_folder, filename))\n",
    "\n",
    "    ground_name = filename[:-5] + \"_SeaErra_abs_depth.tif\"\n",
    "    ground_truth_path = os.path.join(depth_folder, ground_name)\n",
    "    gt_image = Image.open(ground_truth_path)\n",
    "    gt = np.array(gt_image)\n",
    "    formatted_gt = (gt * 255 / np.max(output)).astype(\"uint8\")\n",
    "    ground_truth = Image.fromarray(formatted_gt)\n",
    "    \n",
    "    # save the prediction in a pretty way\n",
    "    fig, ax = plt.subplots(1, 3, dpi=400)\n",
    "\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('FLSea')\n",
    "    ax[1].imshow(depth, cmap= 'plasma')\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('DepthAnything')\n",
    "    ax[2].imshow(ground_truth, cmap= 'plasma_r')\n",
    "    ax[2].axis('off')\n",
    "    ax[2].set_title('Ground Truth')\n",
    "    \n",
    "    fig.savefig(os.path.join(pretty_folder, filename))\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
